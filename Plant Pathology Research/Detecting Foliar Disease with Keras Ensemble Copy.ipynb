{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Plant Pathology 2020 - FGVC7\nIdentify the category of foliar diseases in apple trees\n\nKaggle competition - https://www.kaggle.com/c/plant-pathology-2020-fgvc7/submit","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nprint(tf.__version__)\nimport os\nimport shutil\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.framework.ops import Tensor\nfrom typing import Tuple, List\nimport glob\nimport numpy as np\nimport os\nimport keras\nfrom keras.engine import training\nfrom keras.models import Model, Input\nfrom keras.callbacks import History\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.layers import Average\nfrom keras.layers import Activation\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/tpu-trained-test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VGG16_WEIGHT_FILE = os.path.join(os.getcwd(), '../input/tpu-trained-test', 'vgg16(224).hdf5')\nEFN_WEIGHT_FILE = os.path.join(os.getcwd(),'../input/tpu-trained-test','efn(224).hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MOBILE_NET_WEIGHT_FILE = os.path.join(os.getcwd(), '../input/pretrained-models', 'mobilenet_cnn.hdf5')\n# VGG16_WEIGHT_FILE = os.path.join(os.getcwd(), '../input/pretrained-models', 'vgg16_cnn.hdf5')\n# EFN_WEIGHT_FILE = os.path.join(os.getcwd(),'../input/pretrained-models','efn_cnn.hdf5')\n# DENSE_NET_WEIGHT_FILE = os.path.join(os.getcwd(),'../input/pretrained-models','densenet_cnn.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Data and Preprocessing\n\nHere we load the data and take a look at what we're dealing with.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')\n\n\ntarget = train[['healthy', 'multiple_diseases', 'rust', 'scab']]\ntest_ids = test['image_id']\n\ntrain_len = train.shape[0]\ntest_len = test.shape[0]\n\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ah, we see the multiple_diseases label has drastically less images than the rest of the labels. Once we load the images in raw data form, we'll use scikitlearn to randomly over sample so we can fix this class imbalance.\n\nNow let's load the image data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of train data: \" + str(train.shape))\nprint(\"Shape of test data: \" + str(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_len = train.shape[0]\ntest_len = test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom tqdm.notebook import tqdm\n\npath = '../input/plant-pathology-2020-fgvc7/images/'\nsize = 224\n\ntrain_images = np.ndarray(shape=(train_len, size, size, 3))\nfor i in tqdm(range(train_len)):\n  img = load_img(path + f'Train_{i}.jpg', target_size=(size, size))\n  train_images[i] = np.uint8(img_to_array(img))\n\ntest_images = np.ndarray(shape=(test_len, size, size, 3))\nfor i in tqdm(range(test_len)):\n  img = load_img(path + f'Test_{i}.jpg', target_size=(size, size))\n  test_images[i] = np.uint8(img_to_array(img))\n\ntrain_images.shape, test_images.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at what the images look like.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(4):\n\tplt.subplot(220 + 1 + i)\n\tplt.title(train['image_id'][i])\n\tplt.imshow(np.uint8(train_images[i]), interpolation = 'nearest', aspect='auto')\nplt.show()\nplt.savefig('train_images.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(4):\n\tplt.subplot(220 + 1 + i)\n\tplt.title(test['image_id'][i])\n\tplt.imshow(np.uint8(test_images[i]), interpolation = 'nearest', aspect='auto')\nplt.show()\nplt.savefig('test_images.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's split out data into train and test sets for the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(train_images, target.to_numpy(), test_size=0.1, random_state=289) \n\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now use RandomOverSampler to fix our class imbalance in the multiple diseases class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler(random_state=289)\n\nx_train, y_train = ros.fit_resample(x_train.reshape((-1, size * size * 3)), y_train)\nx_train = x_train.reshape((-1, size, size, 3))\nx_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\n\ndel train_images\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we prepare the data for going into a Keras deep learning model. Here I use the ImageDataGenerator to also give us more images by using the parameters to rotate, horizontally flip, and vertically flip. Also the image is samplewise standard normalized the raw data so that the activation functions work properly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras_preprocessing.image import ImageDataGenerator\n\nbatch_size = 8\n\ntrain_datagen = ImageDataGenerator(samplewise_center = True,\n                                   samplewise_std_normalization = True,\n                                   horizontal_flip = True,\n                                   shear_range=0.1,\n                                   zoom_range=0.3,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   vertical_flip = True,\n                                   brightness_range = [0.1,0.2],\n                                   rotation_range=70)\n\ntrain_generator = train_datagen.flow(\n    x = x_train, \n    y = y_train,\n    batch_size = batch_size)\n\nvalidation_datagen = ImageDataGenerator(samplewise_center = True,\n                                        samplewise_std_normalization = True)\n\nvalidation_generator = validation_datagen.flow(\n    x = x_test, \n    y = y_test,\n    batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see what the images look like after processing and what they look like going into the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = np.random.randint(8)\nx, y = train_generator.__getitem__(idx)\nplt.title(y[idx])\nplt.imshow(x[idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keras Model\nHere we build the model. I will use a pre-trained MobileNet for deep CNN which will then be fed into a dense layer to predict 4 classes, since the original MobileNet predicts 1000. It will compile using the loss function KL Divergence, Adam optimizer, and accuracy metric.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('x_train shape: {} | y_train shape: {}\\nx_test shape : {} | y_test shape : {}'.format(x_train.shape, y_train.shape,\n                                                                                          x_test.shape, y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = x_train[0,:,:,:].shape\nmodel_input = Input(shape=input_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_input","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MobileNet Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"### TESTING\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average\n\ndef mobilenet_cnn(model_input: Tensor) -> training.Model:\n    \n    x = keras.applications.MobileNet(input_shape=(size, size, 3), weights='imagenet', include_top=False)(model_input)\n#     x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(4, (1, 1))(x) # Four feature Maps\n    x = GlobalAveragePooling2D()(x)\n    x = Activation(activation='softmax')(x)\n    \n    model = Model(model_input, x, name='mobilenet_cnn')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def mobilenet_cnn(model_input: Tensor) -> training.Model:\n#     pre_trained = keras.applications.MobileNet(input_shape=(size, size, 3), weights='imagenet', include_top=False)\n#     for layer in pre_trained.layers:\n#         layer.trainable = False\n    \n#     #pretrained_model = tf.keras.applications.mobilenet.MobileNet(input_shape=(SIZE,SIZE,3), include_top=False)\n#     mobilenetmodel = keras.Sequential([\n#       pre_trained,\n#       keras.layers.Flatten(),\n#       keras.layers.GlobalAveragePooling2D(),\n#       keras.layers.Dropout(0.3),\n#       keras.layers.Dense(4,activation='softmax')\n#       ])\n#     return mobilenetmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mobilenet_cnn_model = mobilenet_cnn(model_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 15\nsteps_per_epoch = x_train.shape[0] // batch_size\nvalidation_steps = x_test.shape[0] // batch_size\nprint(steps_per_epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nes = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True, verbose=1)\nrlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, verbose=1)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,verbose=1,min_lr=0.000001,patience=6)\n\n\nstart_lr = 0.00001\nmin_lr = 0.00001\nmax_lr = 0.00005\nrampup_epochs = 40\nsustain_epochs = 20\nexp_decay = .8\n\ndef lrfn(epoch):\n  if epoch < rampup_epochs:\n    return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n  elif epoch < rampup_epochs + sustain_epochs:\n    return max_lr\n  else:\n    return min_lr\n    \nlr = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n\nrang = np.arange(epochs)\ny = [lrfn(x) for x in rang]\nplt.plot(rang, y)\nprint('Learning rate per epoch:')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef compile_and_train(model: training.Model, num_epochs: int) -> Tuple [History, str]: \n    \n    \n    model.compile(\n        loss = 'categorical_crossentropy', \n        optimizer = 'adam', \n        metrics = ['accuracy'])\n    \n    filepath = '/kaggle/working/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n#     checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True,\n#                                                  save_best_only=True, mode='auto', period=1)\n    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True,save_weights_only=True,mode='min')\n    \n    \n    history = model.fit(\n    x = train_generator,  \n    validation_data = validation_generator,\n    epochs = epochs,\n    steps_per_epoch = steps_per_epoch,\n    validation_steps = validation_steps,\n    verbose=1,\n    callbacks=[checkpoint,reduce_lr])\n    \n    \n    weight_files = glob.glob(os.path.join(os.getcwd(), '/kaggle/working/*'))\n    weight_file = max(weight_files, key=os.path.getctime) # most recent file\n    return history, weight_file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"_, mobilenet_cnn_weight_file = compile_and_train(mobilenet_cnn_model, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_error(model: training.Model) -> np.float64:\n    pred = model.predict(x_test, batch_size = 32)\n    pred = np.argmax(pred, axis=1)\n    pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n    error = np.sum(np.not_equal(pred, y_test)) / y_test.shape[0]    \n    return error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    mobilenet_cnn_weight_file\nexcept NameError:\n    mobilenet_cnn_model.load_weights(MOBILE_NET_WEIGHT_FILE)\nevaluate_error(mobilenet_cnn_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Second Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D,GlobalAveragePooling2D,Activation\ndef get_model():\n    base_model = tf.keras.applications.VGG16(weights='imagenet',\n                          include_top=False,\n                          input_shape=(IMG_SIZE,IMG_SIZE, 3))\n    x =  Conv2D(nb_classes, (1, 1))(base_model.output)\n    x = GlobalAveragePooling2D()(x)\n    x = Activation(activation='softmax')(x)\n    return Model(inputs=base_model.input, outputs=x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### TESTING\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average\n\ndef vgg16_cnn(model_input: Tensor) -> training.Model:\n    \n    x = keras.applications.VGG16(input_shape=(size, size, 3), weights='imagenet', include_top=False)(model_input)\n#     x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(4, (1, 1))(x) # Four feature Maps\n    x = GlobalAveragePooling2D()(x)\n    x = Activation(activation='softmax')(x)\n    \n    model = Model(model_input, x, name='mobilenet_cnn')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def vgg16_cnn(model_input: Tensor) -> training.Model:\n#     pre_trained = keras.applications.MobileNet(input_shape=(size, size, 3), weights='imagenet', include_top=False)\n#     for layer in pre_trained.layers:\n#         layer.trainable = False\n    \n#     #pretrained_model = tf.keras.applications.mobilenet.MobileNet(input_shape=(SIZE,SIZE,3), include_top=False)\n#     vgg16model = keras.Sequential([\n#       pre_trained,\n# #       keras.layers.Flatten(),\n# #       keras.layers.Dropout(0.3),\n#       keras.layers.GlobalAveragePooling2D(),\n#       keras.layers.Dense(4, activation='softmax')\n#       ])\n#     return vgg16model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg16_cnn_model = vgg16_cnn_tpu(model_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg16_cnn_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, vgg16_cnn_weight_file = compile_and_train(vgg16_cnn_model, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    vgg16_cnn_weight_file\nexcept NameError:\n    vgg16_cnn_model.load_weights(VGG16_WEIGHT_FILE)\nevaluate_error(vgg16_cnn_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Efficient Net Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import efficientnet.keras as efn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### TESTING\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average\n\ndef efn_cnn(model_input: Tensor) -> training.Model:\n    \n    x  = efn.EfficientNetB7(input_shape=(size, size, 3), weights='imagenet', include_top=False)(model_input)\n    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(4, (1, 1))(x) # Four feature Maps\n    x = GlobalAveragePooling2D()(x)\n    x = Activation(activation='softmax')(x)\n    \n    model = Model(model_input, x, name='mobilenet_cnn')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"efn_cnn_model = efn_cnn(model_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, efn_cnn_weight_file = compile_and_train(efn_cnn_model, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    efn_cnn_weight_file\nexcept NameError:\n    efn_cnn_model.load_weights(EFN_WEIGHT_FILE)\nevaluate_error(efn_cnn_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RESNET50","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"### TESTING\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average\n\ndef resnet_cnn(model_input: Tensor) -> training.Model:\n    \n    x  = keras.applications.ResNet50(input_shape=(size, size, 3), weights='imagenet', include_top=False)(model_input)\n    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n    x = Conv2D(4, (1, 1))(x) # Four feature Maps\n    x = GlobalAveragePooling2D()(x)\n    x = Activation(activation='softmax')(x)\n    \n    model = Model(model_input, x, name='reset_cnn')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_cnn_model = resnet_cnn(model_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, resnet_cnn_weight_file = compile_and_train(resnet_cnn_model, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    resnet_cnn_weight_file\nexcept NameError:\n    resnet_cnn_model.load_weights(DENSE_NET_WEIGHT_FILE)\nevaluate_error(resnet_cnn_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmobilenet_cnn_model = mobilenet_cnn(model_input)\nvgg16_cnn_model = vgg16_cnn(model_input)\nefn_cnn_model = efn_cnn(model_input)\nresnet_cnn_model = resnet_cnn(model_input)\n\n\ntry:\n    mobilenet_cnn_model.load_weights(mobilenet_cnn_weight_file)\nexcept NameError:\n    mobilenet_cnn_model.load_weights(MOBILE_NET_WEIGHT_FILE)\n\ntry:\n    vgg16_cnn_model.load_weights(vgg16_cnn_weight_file)\nexcept NameError:\n    vgg16_cnn_model.load_weights(VGG16_WEIGHT_FILE)\n    \ntry:\n    efn_cnn_model.load_weights(efn_cnn_weight_file)\nexcept NameError:\n    efn_cnn_model.load_weights(EFN_WEIGHT_FILE)\n    \ntry:\n    resnet_cnn_model.load_weights(resnet_cnn_weight_file)\nexcept NameError:\n    resnet_cnn_model.load_weights(DENSE_NET_WEIGHT_FILE)\n\n\n\nmodels = [mobilenet_cnn_model, vgg16_cnn_model,efn_cnn_model,resnet_cnn_model]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ensemble(models: List [training.Model], model_input: Tensor) -> training.Model:\n    \n    outputs = [model.outputs[0] for model in models]\n    y = Average()(outputs)\n    \n    model = Model(model_input, y, name='ensemble')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_model = ensemble(models, model_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_error(ensemble_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pair_A = [efn_cnn_model, resnet_cnn_model]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pair_A_ensemble_model = ensemble(pair_A, model_input)\nevaluate_error(pair_A_ensemble_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# End of Proj","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Weighted Ensemble","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import array\n\n\ndef ensemble_predictions(models: List [training.Model], model_input: Tensor) -> training.Model:\n\t# make predictions\n\toutputs = [model.outputs[0] for model in models]\n\ty = array(outputs)\n\t# sum across ensemble members\n\tsummed = numpy.sum(y, axis=0)\n\t# argmax across classes\n\tresult = argmax(summed, axis=1)\n    model = Model(model_input, result, name='ensemble')\n    \n    \n\treturn model\n\n\n# def ensemble(models: List [training.Model], model_input: Tensor) -> training.Model:\n    \n#     outputs = [model.outputs[0] for model in models]\n#     y = Average()(outputs)\n    \n#     model = Model(model_input, y, name='ensemble')\n    \n#     return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gdgdgdd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fwefwefwffeeffewwqweffffffffffffff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"afasfasfsfsfsfsfs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Plot training & validation accuracy values\n# plt.plot(history.history['accuracy'])\n# plt.plot(history.history['val_accuracy'])\n# plt.title('Model accuracy')\n# plt.ylabel('Accuracy')\n# plt.xlabel('Epoch')\n# plt.legend(['Train', 'Test'], loc='upper left')\n# plt.show()\n\n# # Plot training & validation loss values\n# plt.plot(history.history['loss'])\n# plt.plot(history.history['val_loss'])\n# plt.title('Model loss')\n# plt.ylabel('Loss')\n# plt.xlabel('Epoch')\n# plt.legend(['Train', 'Test'], loc='upper right')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_err = (1-history.history['accuracy'][-1])*100\n# validation_err = (1-history.history['val_accuracy'][-1])*100\n# print(\"Train set error \" + str(train_err))\n# print(\"Validation set error \" + str(validation_err))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(samplewise_center = True,\n                                   samplewise_std_normalization = True,\n                                   horizontal_flip = True,\n                                   shear_range=0.1,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   vertical_flip = True,\n                                   brightness_range = [0.1,0.2],\n                                   rotation_range=70)\n\ntest_generator = test_datagen.flow(\n    x = test_images,\n    shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probabilities = pair_A_ensemble_model.predict(test_generator, steps = len(test_generator))\nprint(probabilities)\nprint(probabilities[:,0].mean()*100)\nprint(probabilities[:,1].mean()*100)\nprint(probabilities[:,2].mean()*100)\nprint(probabilities[:,3].mean()*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame()\nres['image_id'] = test['image_id']\nres['healthy'] = probabilities[:, 0]\nres['multiple_diseases'] = probabilities[:, 1]\nres['rust'] = probabilities[:, 2]\nres['scab'] = probabilities[:, 3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res.to_csv('submission_pairA.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_probabilities = mobilenet_cnn_model.predict(validation_generator, steps = len(validation_generator))\nprint(valid_probabilities[:,0].mean()*100)\nprint(valid_probabilities[:,1].mean()*100)\nprint(valid_probabilities[:,2].mean()*100)\nprint(valid_probabilities[:,3].mean()*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test, valid_probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}