{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet\r\n",
      "  Downloading efficientnet-1.1.0-py3-none-any.whl (18 kB)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from efficientnet) (0.16.2)\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from efficientnet) (1.0.8)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (1.4.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (2.4)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (2.6.1)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (5.4.1)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (1.1.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (3.0.3)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.1)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.14.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (45.2.0.post20200210)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math, re, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import efficientnet.tfkeras as efn\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TPU or GPU detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data access\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "IM_Z = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_path(st):\n",
    "    return GCS_DS_PATH + '/images/' + st + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\n",
    "sub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n",
    "\n",
    "train_paths = train.image_id.apply(format_path).values\n",
    "test_paths = test.image_id.apply(format_path).values\n",
    "\n",
    "train_labels = train.loc[:, 'healthy':].values\n",
    "\n",
    "train_paths, valid_paths, train_labels, valid_labels = train_test_split(\n",
    "    train_paths, train_labels, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IM_Z, IM_Z)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "\n",
    "def data_augment(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "#     image = tf.image.adjust_brightness(image, delta=0.2)\n",
    "#     image = tf.image.adjust_contrast(image,2)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_paths, train_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .repeat()\n",
    "    .shuffle(512)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((valid_paths, valid_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(test_paths)\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lrfn(lr_start=0.00001, lr_max=0.000075, \n",
    "               lr_min=0.000001, lr_rampup_epochs=20, \n",
    "               lr_sustain_epochs=0, lr_exp_decay=.8):\n",
    "    lr_max = lr_max * strategy.num_replicas_in_sync\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    return lrfn\n",
    "\n",
    "ch_p = ModelCheckpoint(filepath=\"model_ef.h5\", monitor='val_loss', save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "258441216/258434480 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        efn.EfficientNetB7(\n",
    "            input_shape=(IM_Z, IM_Z, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        ),\n",
    "        L.GlobalAveragePooling2D(),\n",
    "        L.Dense(train_labels.shape[1], activation='softmax')\n",
    "    ])\n",
    "        \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss = 'categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfn = build_lrfn()\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 25 steps, validate for 3 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/40\n",
      "24/25 [===========================>..] - ETA: 14s - loss: 1.3568 - categorical_accuracy: 0.3568\n",
      "Epoch 00001: saving model to model_ef.h5\n",
      "25/25 [==============================] - 413s 17s/step - loss: 1.3553 - categorical_accuracy: 0.3619 - val_loss: 1.4648 - val_categorical_accuracy: 0.2623\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.95e-05.\n",
      "Epoch 2/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 1.1406 - categorical_accuracy: 0.6582\n",
      "Epoch 00002: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 1.1315 - categorical_accuracy: 0.6644 - val_loss: 1.1136 - val_categorical_accuracy: 0.5792\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 6.9e-05.\n",
      "Epoch 3/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.5654 - categorical_accuracy: 0.8548\n",
      "Epoch 00003: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.5608 - categorical_accuracy: 0.8562 - val_loss: 0.7110 - val_categorical_accuracy: 0.7268\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 9.849999999999998e-05.\n",
      "Epoch 4/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.3390 - categorical_accuracy: 0.8900\n",
      "Epoch 00004: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.3408 - categorical_accuracy: 0.8894 - val_loss: 0.4367 - val_categorical_accuracy: 0.8415\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000128.\n",
      "Epoch 5/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.2806 - categorical_accuracy: 0.9115\n",
      "Epoch 00005: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.2774 - categorical_accuracy: 0.9131 - val_loss: 0.3498 - val_categorical_accuracy: 0.8525\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00015749999999999998.\n",
      "Epoch 6/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.2071 - categorical_accuracy: 0.9310\n",
      "Epoch 00006: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.2071 - categorical_accuracy: 0.9312 - val_loss: 0.2490 - val_categorical_accuracy: 0.9180\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00018699999999999996.\n",
      "Epoch 7/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.2466 - categorical_accuracy: 0.9212\n",
      "Epoch 00007: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.2497 - categorical_accuracy: 0.9200 - val_loss: 0.2449 - val_categorical_accuracy: 0.9071\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00021649999999999998.\n",
      "Epoch 8/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1754 - categorical_accuracy: 0.9427\n",
      "Epoch 00008: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1714 - categorical_accuracy: 0.9437 - val_loss: 0.4907 - val_categorical_accuracy: 0.8689\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00024599999999999996.\n",
      "Epoch 9/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1749 - categorical_accuracy: 0.9395\n",
      "Epoch 00009: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1730 - categorical_accuracy: 0.9400 - val_loss: 0.2265 - val_categorical_accuracy: 0.9508\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0002755.\n",
      "Epoch 10/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1563 - categorical_accuracy: 0.9531\n",
      "Epoch 00010: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1541 - categorical_accuracy: 0.9537 - val_loss: 0.3436 - val_categorical_accuracy: 0.8907\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000305.\n",
      "Epoch 11/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1371 - categorical_accuracy: 0.9538\n",
      "Epoch 00011: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1386 - categorical_accuracy: 0.9544 - val_loss: 0.2049 - val_categorical_accuracy: 0.9454\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003345.\n",
      "Epoch 12/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1224 - categorical_accuracy: 0.9622\n",
      "Epoch 00012: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1210 - categorical_accuracy: 0.9631 - val_loss: 0.2521 - val_categorical_accuracy: 0.9344\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00036399999999999996.\n",
      "Epoch 13/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1226 - categorical_accuracy: 0.9583\n",
      "Epoch 00013: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1208 - categorical_accuracy: 0.9587 - val_loss: 0.2935 - val_categorical_accuracy: 0.9399\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00039349999999999997.\n",
      "Epoch 14/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1015 - categorical_accuracy: 0.9668\n",
      "Epoch 00014: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1017 - categorical_accuracy: 0.9669 - val_loss: 0.2691 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.000423.\n",
      "Epoch 15/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1098 - categorical_accuracy: 0.9603\n",
      "Epoch 00015: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.1130 - categorical_accuracy: 0.9581 - val_loss: 0.1678 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00045249999999999994.\n",
      "Epoch 16/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0887 - categorical_accuracy: 0.9707\n",
      "Epoch 00016: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.0867 - categorical_accuracy: 0.9712 - val_loss: 0.3104 - val_categorical_accuracy: 0.9454\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00048199999999999995.\n",
      "Epoch 17/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0776 - categorical_accuracy: 0.9727\n",
      "Epoch 00017: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.0748 - categorical_accuracy: 0.9737 - val_loss: 0.2015 - val_categorical_accuracy: 0.9617\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005114999999999999.\n",
      "Epoch 18/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0682 - categorical_accuracy: 0.9779\n",
      "Epoch 00018: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.0663 - categorical_accuracy: 0.9787 - val_loss: 0.3471 - val_categorical_accuracy: 0.9454\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005409999999999999.\n",
      "Epoch 19/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0867 - categorical_accuracy: 0.9733\n",
      "Epoch 00019: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.0900 - categorical_accuracy: 0.9737 - val_loss: 0.3670 - val_categorical_accuracy: 0.9454\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005704999999999999.\n",
      "Epoch 20/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1203 - categorical_accuracy: 0.9609\n",
      "Epoch 00020: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.1182 - categorical_accuracy: 0.9619 - val_loss: 0.3463 - val_categorical_accuracy: 0.9235\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 21/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0931 - categorical_accuracy: 0.9694\n",
      "Epoch 00021: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0900 - categorical_accuracy: 0.9706 - val_loss: 0.2546 - val_categorical_accuracy: 0.9399\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.00048019999999999996.\n",
      "Epoch 22/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0973 - categorical_accuracy: 0.9701\n",
      "Epoch 00022: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0957 - categorical_accuracy: 0.9706 - val_loss: 0.2436 - val_categorical_accuracy: 0.9454\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00038436000000000004.\n",
      "Epoch 23/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0795 - categorical_accuracy: 0.9746\n",
      "Epoch 00023: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0790 - categorical_accuracy: 0.9744 - val_loss: 0.1647 - val_categorical_accuracy: 0.9617\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003076880000000001.\n",
      "Epoch 24/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0462 - categorical_accuracy: 0.9876\n",
      "Epoch 00024: saving model to model_ef.h5\n",
      "25/25 [==============================] - 32s 1s/step - loss: 0.0446 - categorical_accuracy: 0.9881 - val_loss: 0.1672 - val_categorical_accuracy: 0.9617\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0002463504.\n",
      "Epoch 25/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0284 - categorical_accuracy: 0.9922\n",
      "Epoch 00025: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0281 - categorical_accuracy: 0.9925 - val_loss: 0.1573 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00019728032000000003.\n",
      "Epoch 26/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0198 - categorical_accuracy: 0.9941\n",
      "Epoch 00026: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0199 - categorical_accuracy: 0.9937 - val_loss: 0.1955 - val_categorical_accuracy: 0.9563\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00015802425600000002.\n",
      "Epoch 27/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0140 - categorical_accuracy: 0.9954\n",
      "Epoch 00027: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0136 - categorical_accuracy: 0.9956 - val_loss: 0.1458 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0001266194048.\n",
      "Epoch 28/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0104 - categorical_accuracy: 0.9974\n",
      "Epoch 00028: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0114 - categorical_accuracy: 0.9969 - val_loss: 0.1356 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00010149552384000004.\n",
      "Epoch 29/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0084 - categorical_accuracy: 0.9987\n",
      "Epoch 00029: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0085 - categorical_accuracy: 0.9987 - val_loss: 0.1333 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0087 - categorical_accuracy: 0.9987\n",
      "Epoch 00030: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0085 - categorical_accuracy: 0.9987 - val_loss: 0.1445 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 6.531713525760003e-05.\n",
      "Epoch 31/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0066 - categorical_accuracy: 0.9987\n",
      "Epoch 00031: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0072 - categorical_accuracy: 0.9987 - val_loss: 0.1575 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 5.2453708206080024e-05.\n",
      "Epoch 32/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0050 - categorical_accuracy: 1.0000\n",
      "Epoch 00032: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0050 - categorical_accuracy: 1.0000 - val_loss: 0.1509 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 4.2162966564864016e-05.\n",
      "Epoch 33/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0099 - categorical_accuracy: 0.9974\n",
      "Epoch 00033: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0096 - categorical_accuracy: 0.9975 - val_loss: 0.1465 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 3.3930373251891216e-05.\n",
      "Epoch 34/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0043 - categorical_accuracy: 1.0000\n",
      "Epoch 00034: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0043 - categorical_accuracy: 1.0000 - val_loss: 0.1451 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 2.734429860151298e-05.\n",
      "Epoch 35/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0082 - categorical_accuracy: 0.9980\n",
      "Epoch 00035: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0079 - categorical_accuracy: 0.9981 - val_loss: 0.1430 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.2075438881210384e-05.\n",
      "Epoch 36/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0098 - categorical_accuracy: 0.9974\n",
      "Epoch 00036: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0095 - categorical_accuracy: 0.9975 - val_loss: 0.1386 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.7860351104968306e-05.\n",
      "Epoch 37/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0056 - categorical_accuracy: 0.9980\n",
      "Epoch 00037: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0054 - categorical_accuracy: 0.9981 - val_loss: 0.1357 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.4488280883974648e-05.\n",
      "Epoch 38/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0050 - categorical_accuracy: 0.9987\n",
      "Epoch 00038: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0049 - categorical_accuracy: 0.9987 - val_loss: 0.1343 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.179062470717972e-05.\n",
      "Epoch 39/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0046 - categorical_accuracy: 0.9987\n",
      "Epoch 00039: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0054 - categorical_accuracy: 0.9981 - val_loss: 0.1358 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 9.632499765743775e-06.\n",
      "Epoch 40/40\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.0072 - categorical_accuracy: 0.9980\n",
      "Epoch 00040: saving model to model_ef.h5\n",
      "25/25 [==============================] - 31s 1s/step - loss: 0.0070 - categorical_accuracy: 0.9981 - val_loss: 0.1380 - val_categorical_accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[lr_schedule, ch_p],\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_data=valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model1 = tf.keras.Sequential([\n",
    "        tf.keras.applications.DenseNet201(\n",
    "            input_shape=(IM_Z, IM_Z, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        ),\n",
    "        L.GlobalAveragePooling2D(),\n",
    "        L.Dense(train_labels.shape[1], activation='softmax')\n",
    "    ])\n",
    "        \n",
    "             \n",
    "    model1.compile(\n",
    "        optimizer='adam',\n",
    "        loss = 'categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_p_den = ModelCheckpoint(filepath=\"model_den.h5\", monitor='val_loss', save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 25 steps, validate for 3 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/40\n",
      "24/25 [===========================>..] - ETA: 10s - loss: 1.3612 - categorical_accuracy: 0.3587\n",
      "Epoch 00001: saving model to model_den.h5\n",
      "25/25 [==============================] - 343s 14s/step - loss: 1.3558 - categorical_accuracy: 0.3612 - val_loss: 1.3310 - val_categorical_accuracy: 0.4645\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.95e-05.\n",
      "Epoch 2/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.7023 - categorical_accuracy: 0.7643\n",
      "Epoch 00002: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 889ms/step - loss: 0.6874 - categorical_accuracy: 0.7681 - val_loss: 0.7804 - val_categorical_accuracy: 0.6612\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 6.9e-05.\n",
      "Epoch 3/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.3682 - categorical_accuracy: 0.8835\n",
      "Epoch 00003: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 899ms/step - loss: 0.3661 - categorical_accuracy: 0.8844 - val_loss: 0.7144 - val_categorical_accuracy: 0.6448\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 9.849999999999998e-05.\n",
      "Epoch 4/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.2751 - categorical_accuracy: 0.9043\n",
      "Epoch 00004: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 882ms/step - loss: 0.2796 - categorical_accuracy: 0.9019 - val_loss: 0.3265 - val_categorical_accuracy: 0.8852\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000128.\n",
      "Epoch 5/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1881 - categorical_accuracy: 0.9414\n",
      "Epoch 00005: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 886ms/step - loss: 0.1867 - categorical_accuracy: 0.9412 - val_loss: 0.3022 - val_categorical_accuracy: 0.8852\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00015749999999999998.\n",
      "Epoch 6/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1395 - categorical_accuracy: 0.9577\n",
      "Epoch 00006: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 901ms/step - loss: 0.1407 - categorical_accuracy: 0.9575 - val_loss: 0.2358 - val_categorical_accuracy: 0.9508\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00018699999999999996.\n",
      "Epoch 7/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1071 - categorical_accuracy: 0.9688\n",
      "Epoch 00007: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 900ms/step - loss: 0.1055 - categorical_accuracy: 0.9694 - val_loss: 0.5441 - val_categorical_accuracy: 0.8798\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00021649999999999998.\n",
      "Epoch 8/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1675 - categorical_accuracy: 0.9492\n",
      "Epoch 00008: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 893ms/step - loss: 0.1639 - categorical_accuracy: 0.9500 - val_loss: 0.8511 - val_categorical_accuracy: 0.7268\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00024599999999999996.\n",
      "Epoch 9/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1229 - categorical_accuracy: 0.9688\n",
      "Epoch 00009: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 916ms/step - loss: 0.1251 - categorical_accuracy: 0.9669 - val_loss: 0.5912 - val_categorical_accuracy: 0.7596\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0002755.\n",
      "Epoch 10/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1131 - categorical_accuracy: 0.9661\n",
      "Epoch 00010: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 898ms/step - loss: 0.1117 - categorical_accuracy: 0.9663 - val_loss: 0.5708 - val_categorical_accuracy: 0.9180\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000305.\n",
      "Epoch 11/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0931 - categorical_accuracy: 0.9694\n",
      "Epoch 00011: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 897ms/step - loss: 0.0907 - categorical_accuracy: 0.9706 - val_loss: 0.2452 - val_categorical_accuracy: 0.9399\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003345.\n",
      "Epoch 12/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0868 - categorical_accuracy: 0.9772\n",
      "Epoch 00012: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 894ms/step - loss: 0.0876 - categorical_accuracy: 0.9775 - val_loss: 0.1874 - val_categorical_accuracy: 0.9399\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00036399999999999996.\n",
      "Epoch 13/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0903 - categorical_accuracy: 0.9720\n",
      "Epoch 00013: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 908ms/step - loss: 0.0915 - categorical_accuracy: 0.9706 - val_loss: 1.1477 - val_categorical_accuracy: 0.6503\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00039349999999999997.\n",
      "Epoch 14/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1162 - categorical_accuracy: 0.9661\n",
      "Epoch 00014: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 899ms/step - loss: 0.1133 - categorical_accuracy: 0.9669 - val_loss: 0.5819 - val_categorical_accuracy: 0.8415\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.000423.\n",
      "Epoch 15/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1070 - categorical_accuracy: 0.9596\n",
      "Epoch 00015: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 897ms/step - loss: 0.1073 - categorical_accuracy: 0.9594 - val_loss: 1.9868 - val_categorical_accuracy: 0.5137\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00045249999999999994.\n",
      "Epoch 16/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0951 - categorical_accuracy: 0.9668\n",
      "Epoch 00016: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 910ms/step - loss: 0.0949 - categorical_accuracy: 0.9669 - val_loss: 0.7378 - val_categorical_accuracy: 0.8361\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00048199999999999995.\n",
      "Epoch 17/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0770 - categorical_accuracy: 0.9740\n",
      "Epoch 00017: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 901ms/step - loss: 0.0748 - categorical_accuracy: 0.9750 - val_loss: 0.6427 - val_categorical_accuracy: 0.7760\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005114999999999999.\n",
      "Epoch 18/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0805 - categorical_accuracy: 0.9733\n",
      "Epoch 00018: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 894ms/step - loss: 0.0787 - categorical_accuracy: 0.9744 - val_loss: 0.6152 - val_categorical_accuracy: 0.8415\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005409999999999999.\n",
      "Epoch 19/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0890 - categorical_accuracy: 0.9674\n",
      "Epoch 00019: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 893ms/step - loss: 0.0901 - categorical_accuracy: 0.9669 - val_loss: 0.7971 - val_categorical_accuracy: 0.8470\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005704999999999999.\n",
      "Epoch 20/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1308 - categorical_accuracy: 0.9557\n",
      "Epoch 00020: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 906ms/step - loss: 0.1300 - categorical_accuracy: 0.9562 - val_loss: 0.7358 - val_categorical_accuracy: 0.7760\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 21/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1776 - categorical_accuracy: 0.9421\n",
      "Epoch 00021: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 894ms/step - loss: 0.1782 - categorical_accuracy: 0.9412 - val_loss: 0.4650 - val_categorical_accuracy: 0.9344\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.00048019999999999996.\n",
      "Epoch 22/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1028 - categorical_accuracy: 0.9668\n",
      "Epoch 00022: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 922ms/step - loss: 0.1053 - categorical_accuracy: 0.9669 - val_loss: 0.2199 - val_categorical_accuracy: 0.9617\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00038436000000000004.\n",
      "Epoch 23/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0456 - categorical_accuracy: 0.9883\n",
      "Epoch 00023: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 935ms/step - loss: 0.0443 - categorical_accuracy: 0.9887 - val_loss: 0.1878 - val_categorical_accuracy: 0.9399\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003076880000000001.\n",
      "Epoch 24/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0297 - categorical_accuracy: 0.9902\n",
      "Epoch 00024: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 899ms/step - loss: 0.0293 - categorical_accuracy: 0.9906 - val_loss: 0.1961 - val_categorical_accuracy: 0.9399\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0002463504.\n",
      "Epoch 25/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0180 - categorical_accuracy: 0.9967\n",
      "Epoch 00025: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 892ms/step - loss: 0.0175 - categorical_accuracy: 0.9969 - val_loss: 0.1041 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00019728032000000003.\n",
      "Epoch 26/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0149 - categorical_accuracy: 0.9967\n",
      "Epoch 00026: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 901ms/step - loss: 0.0154 - categorical_accuracy: 0.9962 - val_loss: 0.0918 - val_categorical_accuracy: 0.9781\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00015802425600000002.\n",
      "Epoch 27/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0130 - categorical_accuracy: 0.9967\n",
      "Epoch 00027: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 898ms/step - loss: 0.0127 - categorical_accuracy: 0.9969 - val_loss: 0.1066 - val_categorical_accuracy: 0.9672\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0001266194048.\n",
      "Epoch 28/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0075 - categorical_accuracy: 0.9993\n",
      "Epoch 00028: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 901ms/step - loss: 0.0074 - categorical_accuracy: 0.9994 - val_loss: 0.1087 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00010149552384000004.\n",
      "Epoch 29/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0050 - categorical_accuracy: 1.0000\n",
      "Epoch 00029: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 905ms/step - loss: 0.0049 - categorical_accuracy: 1.0000 - val_loss: 0.1120 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0080 - categorical_accuracy: 0.9993\n",
      "Epoch 00030: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 897ms/step - loss: 0.0078 - categorical_accuracy: 0.9994 - val_loss: 0.1051 - val_categorical_accuracy: 0.9781\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 6.531713525760003e-05.\n",
      "Epoch 31/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0062 - categorical_accuracy: 0.9993\n",
      "Epoch 00031: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 893ms/step - loss: 0.0060 - categorical_accuracy: 0.9994 - val_loss: 0.1040 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 5.2453708206080024e-05.\n",
      "Epoch 32/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0052 - categorical_accuracy: 1.0000\n",
      "Epoch 00032: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 910ms/step - loss: 0.0051 - categorical_accuracy: 1.0000 - val_loss: 0.1060 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 4.2162966564864016e-05.\n",
      "Epoch 33/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0040 - categorical_accuracy: 1.0000\n",
      "Epoch 00033: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 906ms/step - loss: 0.0039 - categorical_accuracy: 1.0000 - val_loss: 0.1073 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 3.3930373251891216e-05.\n",
      "Epoch 34/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0028 - categorical_accuracy: 1.0000\n",
      "Epoch 00034: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 911ms/step - loss: 0.0028 - categorical_accuracy: 1.0000 - val_loss: 0.1076 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 2.734429860151298e-05.\n",
      "Epoch 35/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0039 - categorical_accuracy: 1.0000\n",
      "Epoch 00035: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 898ms/step - loss: 0.0038 - categorical_accuracy: 1.0000 - val_loss: 0.1087 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.2075438881210384e-05.\n",
      "Epoch 36/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0064 - categorical_accuracy: 0.9987\n",
      "Epoch 00036: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 911ms/step - loss: 0.0063 - categorical_accuracy: 0.9987 - val_loss: 0.1093 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.7860351104968306e-05.\n",
      "Epoch 37/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0041 - categorical_accuracy: 1.0000\n",
      "Epoch 00037: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 928ms/step - loss: 0.0040 - categorical_accuracy: 1.0000 - val_loss: 0.1093 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.4488280883974648e-05.\n",
      "Epoch 38/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0102 - categorical_accuracy: 0.9980\n",
      "Epoch 00038: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 904ms/step - loss: 0.0100 - categorical_accuracy: 0.9981 - val_loss: 0.1104 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.179062470717972e-05.\n",
      "Epoch 39/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0048 - categorical_accuracy: 1.0000\n",
      "Epoch 00039: saving model to model_den.h5\n",
      "25/25 [==============================] - 22s 895ms/step - loss: 0.0047 - categorical_accuracy: 1.0000 - val_loss: 0.1113 - val_categorical_accuracy: 0.9727\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 9.632499765743775e-06.\n",
      "Epoch 40/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.0115 - categorical_accuracy: 0.9974\n",
      "Epoch 00040: saving model to model_den.h5\n",
      "25/25 [==============================] - 23s 902ms/step - loss: 0.0116 - categorical_accuracy: 0.9975 - val_loss: 0.1113 - val_categorical_accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(\n",
    "    train_dataset, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[lr_schedule, ch_p_den],\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_data=valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"model_ef.h5\")\n",
    "# model.load_weights(\"model_den.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = model.predict(test_dataset, verbose=1)\n",
    "probs = (model1.predict(test_dataset)+model.predict(test_dataset))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0</td>\n",
       "      <td>1.293858e-05</td>\n",
       "      <td>2.599403e-03</td>\n",
       "      <td>0.997371</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_1</td>\n",
       "      <td>7.660828e-05</td>\n",
       "      <td>6.128404e-05</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_2</td>\n",
       "      <td>2.546491e-07</td>\n",
       "      <td>3.763144e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_3</td>\n",
       "      <td>9.998404e-01</td>\n",
       "      <td>1.545112e-06</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_4</td>\n",
       "      <td>8.315535e-06</td>\n",
       "      <td>1.649597e-03</td>\n",
       "      <td>0.998317</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id       healthy  multiple_diseases      rust      scab\n",
       "0   Test_0  1.293858e-05       2.599403e-03  0.997371  0.000016\n",
       "1   Test_1  7.660828e-05       6.128404e-05  0.999833  0.000029\n",
       "2   Test_2  2.546491e-07       3.763144e-07  0.000002  0.999998\n",
       "3   Test_3  9.998404e-01       1.545112e-06  0.000066  0.000092\n",
       "4   Test_4  8.315535e-06       1.649597e-03  0.998317  0.000026"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[:, 'healthy':] = probs\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
